#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†é‡å¤çš„æ–‡æ¡£æ•°æ®
- ä¿ç•™æ¯ä¸ªæ–‡ä»¶åçš„æœ€æ–°è®°å½•
- åˆ é™¤PostgreSQLä¸­çš„é‡å¤æ•°æ®
- åˆ é™¤ChromaDBä¸­å¯¹åº”çš„å‘é‡
"""

import os
import sys
import psycopg2

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

from services.vector_db_service import VectorDBService

DATABASE_URL = "postgresql://postgres:123456@localhost:5432/app_project"

def clean_duplicates():
    """æ¸…ç†é‡å¤çš„æ–‡æ¡£æ•°æ®"""
    
    print("=" * 80)
    print("ğŸ” æŸ¥æ‰¾å¹¶æ¸…ç†é‡å¤çš„æ–‡æ¡£")
    print("=" * 80)
    
    try:
        conn = psycopg2.connect(DATABASE_URL)
        conn.autocommit = False
        cursor = conn.cursor()
        
        # 1. æŸ¥æ‰¾é‡å¤çš„æ–‡æ¡£ï¼ˆåŒä¸€è¯¾ç¨‹ä¸‹ç›¸åŒæ–‡ä»¶åï¼‰
        print("\n1ï¸âƒ£ æŸ¥æ‰¾é‡å¤æ–‡æ¡£...")
        cursor.execute("""
            WITH ranked_docs AS (
                SELECT 
                    id,
                    course_id,
                    file_name,
                    created_at,
                    ROW_NUMBER() OVER (
                        PARTITION BY course_id, file_name 
                        ORDER BY created_at DESC
                    ) as rn
                FROM course_documents
            )
            SELECT 
                rd.id,
                rd.course_id,
                rd.file_name,
                rd.created_at,
                c.course_name
            FROM ranked_docs rd
            JOIN courses c ON rd.course_id = c.id
            WHERE rd.rn > 1
            ORDER BY rd.file_name, rd.created_at;
        """)
        
        duplicates = cursor.fetchall()
        
        if not duplicates:
            print("   âœ… æ²¡æœ‰å‘ç°é‡å¤æ–‡æ¡£")
            cursor.close()
            conn.close()
            return
        
        print(f"   âš ï¸  å‘ç° {len(duplicates)} ä¸ªé‡å¤æ–‡æ¡£\n")
        
        # æ˜¾ç¤ºé‡å¤æ–‡æ¡£åˆ—è¡¨å’Œæ–‡ä»¶è·¯å¾„
        print("   é‡å¤æ–‡æ¡£åˆ—è¡¨:")
        duplicate_file_paths = []
        for doc in duplicates:
            doc_id, course_id, file_name, created_at, course_name = doc
            print(f"   - {file_name}")
            print(f"     è¯¾ç¨‹: {course_name}")
            print(f"     ID: {doc_id}")
            print(f"     åˆ›å»ºæ—¶é—´: {created_at}")
            
            # æŸ¥è¯¢æ–‡ä»¶è·¯å¾„
            cursor.execute("SELECT file_path FROM course_documents WHERE id = %s", (doc_id,))
            file_path_result = cursor.fetchone()
            if file_path_result:
                duplicate_file_paths.append((doc_id, file_name, file_path_result[0]))
                print(f"     è·¯å¾„: {file_path_result[0]}\n")
            else:
                print()
        
        # 2. åˆ é™¤æœ¬åœ°ç‰©ç†æ–‡ä»¶
        print("2ï¸âƒ£ åˆ é™¤æœ¬åœ°ç‰©ç†æ–‡ä»¶...")
        
        deleted_files = 0
        failed_files = 0
        
        for doc_id, file_name, file_path in duplicate_file_paths:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    deleted_files += 1
                    print(f"   âœ… åˆ é™¤æ–‡ä»¶: {file_name}")
                except Exception as e:
                    failed_files += 1
                    print(f"   âŒ åˆ é™¤å¤±è´¥ ({file_name}): {e}")
            else:
                print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
        
        print(f"\n   æˆåŠŸåˆ é™¤: {deleted_files} ä¸ªç‰©ç†æ–‡ä»¶")
        if failed_files > 0:
            print(f"   å¤±è´¥: {failed_files} ä¸ª")
        
        # 3. ä»PostgreSQLåˆ é™¤è®°å½•
        print("\n3ï¸âƒ£ ä»PostgreSQLåˆ é™¤é‡å¤æ–‡æ¡£è®°å½•...")
        
        duplicate_ids = [doc[0] for doc in duplicates]  # ä¿æŒUUIDç±»å‹
        
        # åˆ é™¤knowledge_baseä¸­çš„æ•°æ®ï¼ˆæœ‰å¤–é”®ä¾èµ–ï¼‰
        placeholders = ','.join(['%s'] * len(duplicate_ids))
        cursor.execute(f"""
            DELETE FROM knowledge_base
            WHERE document_id IN ({placeholders});
        """, duplicate_ids)
        kb_deleted = cursor.rowcount
        print(f"   âœ… åˆ é™¤knowledge_base: {kb_deleted} æ¡è®°å½•")
        
        # åˆ é™¤course_documentsä¸­çš„æ•°æ®
        cursor.execute(f"""
            DELETE FROM course_documents
            WHERE id IN ({placeholders});
        """, duplicate_ids)
        doc_deleted = cursor.rowcount
        print(f"   âœ… åˆ é™¤course_documents: {doc_deleted} æ¡è®°å½•")
        
        # æäº¤PostgreSQLäº‹åŠ¡
        conn.commit()
        print(f"   âœ… PostgreSQLæ•°æ®å·²æäº¤")
        
        # 4. åˆ é™¤ChromaDBä¸­çš„å‘é‡ï¼ˆåå°å¤„ç†ï¼Œå¦‚æœå¤±è´¥ä¹Ÿä¸å½±å“ï¼‰
        print("\n4ï¸âƒ£ ä»ChromaDBåˆ é™¤é‡å¤æ–‡æ¡£çš„å‘é‡...")
        
        try:
            vector_service = VectorDBService()
            collection = vector_service.course_collection
            
            deleted_vector_count = 0
            
            for doc in duplicates:
                doc_id = str(doc[0])
                file_name = doc[2]
                
                try:
                    # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰å‘é‡ID
                    results = collection.get(
                        where={"document_id": doc_id}
                    )
                    
                    if results and results['ids']:
                        collection.delete(ids=results['ids'])
                        deleted_vector_count += len(results['ids'])
                        print(f"   âœ… åˆ é™¤ {file_name}: {len(results['ids'])} ä¸ªå‘é‡")
                except Exception as e:
                    print(f"   âš ï¸  åˆ é™¤å‘é‡å¤±è´¥ ({file_name}): {e}")
            
            print(f"\n   æ€»è®¡åˆ é™¤ChromaDBå‘é‡: {deleted_vector_count} ä¸ª")
        except Exception as e:
            print(f"   âš ï¸  ChromaDBæ¸…ç†å¤±è´¥: {e}")
            print(f"   æç¤º: å¯ä»¥æ‰‹åŠ¨é‡å¯ChromaDBæˆ–å¿½ç•¥æ­¤é”™è¯¯")
        
        # 5. éªŒè¯ç»“æœ
        print("\n5ï¸âƒ£ éªŒè¯PostgreSQLæ¸…ç†ç»“æœ...")
        
        cursor.execute("""
            SELECT 
                course_id,
                file_name,
                COUNT(*) as count
            FROM course_documents
            GROUP BY course_id, file_name
            HAVING COUNT(*) > 1;
        """)
        
        remaining_duplicates = cursor.fetchall()
        
        if remaining_duplicates:
            print(f"   âš ï¸  ä»æœ‰ {len(remaining_duplicates)} ä¸ªé‡å¤æ–‡æ¡£")
            for dup in remaining_duplicates:
                print(f"   - {dup[1]}: {dup[2]} ä¸ªå‰¯æœ¬")
        else:
            print("   âœ… æ‰€æœ‰é‡å¤æ–‡æ¡£å·²æ¸…ç†å®Œæˆ")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM course_documents;")
        total_docs = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM knowledge_base;")
        total_chunks = cursor.fetchone()[0]
        
        print(f"\nğŸ“Š æ¸…ç†åç»Ÿè®¡:")
        print(f"   æ–‡æ¡£æ€»æ•°: {total_docs}")
        print(f"   æ–‡æœ¬å—æ€»æ•°: {total_chunks}")
        
        # å°è¯•è·å–ChromaDBç»Ÿè®¡ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
        try:
            vector_service = VectorDBService()
            print(f"   ChromaDBå‘é‡æ•°: {vector_service.course_collection.count()}")
        except:
            print(f"   ChromaDBå‘é‡æ•°: (éœ€è¦æ‰‹åŠ¨éªŒè¯)")
        
        cursor.close()
        conn.close()
        
        print("\n" + "=" * 80)
        print("âœ… æ¸…ç†å®Œæˆ!")
        print("=" * 80)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸…ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        if 'conn' in locals():
            conn.rollback()
            conn.close()
        return False

def show_current_documents():
    """æ˜¾ç¤ºå½“å‰æ‰€æœ‰æ–‡æ¡£"""
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ å½“å‰æ–‡æ¡£åˆ—è¡¨")
    print("=" * 80)
    
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                c.course_name,
                cd.file_name,
                cd.created_at,
                COUNT(kb.id) as chunks
            FROM course_documents cd
            JOIN courses c ON cd.course_id = c.id
            LEFT JOIN knowledge_base kb ON cd.id = kb.document_id
            GROUP BY c.course_name, cd.file_name, cd.created_at
            ORDER BY c.course_name, cd.file_name, cd.created_at DESC;
        """)
        
        docs = cursor.fetchall()
        
        if not docs:
            print("\n   æ²¡æœ‰æ–‡æ¡£")
        else:
            current_course = None
            for doc in docs:
                course_name, file_name, created_at, chunks = doc
                
                if course_name != current_course:
                    print(f"\nğŸ“š {course_name}")
                    current_course = course_name
                
                print(f"   - {file_name}")
                print(f"     ä¸Šä¼ æ—¶é—´: {created_at}")
                print(f"     æ–‡æœ¬å—: {chunks} ä¸ª")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

if __name__ == "__main__":
    print("\nğŸš€ å¼€å§‹æ¸…ç†é‡å¤æ–‡æ¡£...\n")
    
    # æ˜¾ç¤ºå½“å‰æ–‡æ¡£
    show_current_documents()
    
    # æ¸…ç†é‡å¤æ•°æ®
    clean_duplicates()
    
    # å†æ¬¡æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
    show_current_documents()
