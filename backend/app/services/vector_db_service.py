"""
å‘é‡æ•°æ®åº“æœåŠ¡
ä½¿ç”¨ LlamaIndex + ChromaDB å®ç° RAG

æ¶æ„ï¼š
- æ ¸å¿ƒï¼šLlamaIndex (VectorStoreIndex)
- å­˜å‚¨ï¼šChromaDB (Persistent)
- æ¨¡å‹ï¼šHuggingFace Embedding (æœ¬åœ°) + OpenAI LLM (è¿œç¨‹)
- ç»“æ„ï¼šæ¯ä¸ªè¯¾ç¨‹å¯¹åº”ä¸€ä¸ª Chroma Collection -> ä¸€ä¸ª VectorStoreIndex
"""
import chromadb
from chromadb.config import Settings as ChromaSettings
from typing import List, Dict, Any, Optional
import os
from datetime import datetime
from pathlib import Path

# LlamaIndex æ ¸å¿ƒç»„ä»¶ï¼ˆæ¡ä»¶å¯¼å…¥ï¼‰
try:
    from llama_index.core import (
        VectorStoreIndex, 
        Document, 
        Settings, 
        StorageContext,
        load_index_from_storage
    )
    from llama_index.vector_stores.chroma import ChromaVectorStore
    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
    from llama_index.llms.openai import OpenAI
    from llama_index.core.query_engine import CitationQueryEngine
    LLAMA_INDEX_AVAILABLE = True
except ImportError:
    print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥ LlamaIndexï¼Œå‘é‡æ•°æ®åº“åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("ğŸ’¡ æç¤º: å¦‚éœ€å¯ç”¨å‘é‡æ•°æ®åº“åŠŸèƒ½ï¼Œè¯·å®‰è£… llama-index ç›¸å…³åŒ…")
    LLAMA_INDEX_AVAILABLE = False
    # å®šä¹‰å ä½ç¬¦ç±»ï¼Œä»¥é˜²éœ€è¦è¿™äº›ç±»çš„ç±»å‹æç¤º
    VectorStoreIndex = None
    Document = None
    Settings = None
    StorageContext = None
    load_index_from_storage = None
    ChromaVectorStore = None
    HuggingFaceEmbedding = None
    OpenAI = None
    CitationQueryEngine = None

class VectorDBService:
    """åŸºäº LlamaIndex çš„å‘é‡æ•°æ®åº“æœåŠ¡"""
    
    def __init__(self):
        if not LLAMA_INDEX_AVAILABLE:
            print("âš ï¸  LlamaIndex ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡æ•°æ®åº“åˆå§‹åŒ–")
            self.available = False
            return
        
        self.available = True
        try:
            # 1. è·¯å¾„é…ç½®
            backend_dir = Path(__file__).resolve().parent.parent.parent
            db_path = backend_dir / "data" / "chroma_db"
            db_path.mkdir(parents=True, exist_ok=True)
            print(f"å‘é‡æ•°æ®åº“è·¯å¾„: {db_path}")
            
            # 2. åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(
                path=str(db_path),
                settings=ChromaSettings(anonymized_telemetry=False)
            )
            
            # 3. é…ç½®å…¨å±€ Settings (LlamaIndex v0.10+)
            print("æ­£åœ¨åˆå§‹åŒ– LlamaIndex æ¨¡å‹é…ç½®...")
            
            # Embedding æ¨¡å‹ (ä¿æŒä¸åŸé¡¹ç›®ä¸€è‡´ï¼Œä½¿ç”¨æœ¬åœ° HuggingFace æ¨¡å‹)
            # cache_folder å¯ä»¥æŒ‡å®šæ¨¡å‹ç¼“å­˜è·¯å¾„ï¼Œé¿å…é‡å¤ä¸‹è½½
            self.embed_model = HuggingFaceEmbedding(
                model_name="paraphrase-multilingual-MiniLM-L12-v2"
            )
            Settings.embed_model = self.embed_model
            
            # LLM é…ç½® (ä½¿ç”¨ OpenAI)
            # æ³¨æ„ï¼šéœ€è¦ç¯å¢ƒå˜é‡ OPENAI_API_KEY
            self.llm = OpenAI(model="gpt-3.5-turbo", temperature=0)
            Settings.llm = self.llm
            
            print("LlamaIndex é…ç½®å®Œæˆ")
            
            # 4. ç´¢å¼•ç¼“å­˜
            self._indices = {} # course_id -> VectorStoreIndex
            self._query_engines = {} # course_id -> QueryEngine
            
            # 5. åˆå§‹åŒ–é»˜è®¤/é—®å·é›†åˆ
            self.survey_collection_name = "survey_documents"
            self._init_collection(self.survey_collection_name, "é—®å·æ–‡æ¡£çŸ¥è¯†åº“")
            
        except Exception as e:
            print(f"å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _init_collection(self, name: str, description: str) -> None:
        """åˆå§‹åŒ– Chroma é›†åˆ"""
        self.client.get_or_create_collection(
            name=name,
            metadata={"description": description}
        )

    def get_index(self, course_id: Optional[str] = None) -> Optional[VectorStoreIndex]:
        if not self.available:
            return None
        """
        è·å–æŒ‡å®šè¯¾ç¨‹çš„ç´¢å¼•å¯¹è±¡
        å¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºå¹¶è¿æ¥åˆ°å¯¹åº”çš„ Chroma Collection
        """
        # ç¡®å®šé›†åˆåç§°
        if course_id:
            collection_name = f"course_{course_id.replace('-', '_')}"
            desc = f"è¯¾ç¨‹ {course_id} çš„ä¸“å±çŸ¥è¯†åº“"
        else:
            collection_name = self.survey_collection_name
            desc = "é—®å·æ–‡æ¡£çŸ¥è¯†åº“"
            
        # æ£€æŸ¥ç¼“å­˜
        if collection_name in self._indices:
            return self._indices[collection_name]
            
        try:
            # è·å– Chroma Collection
            chroma_collection = self.client.get_or_create_collection(
                name=collection_name,
                metadata={"description": desc, "created_at": datetime.now().isoformat()}
            )
            
            # åˆ›å»º Vector Store
            vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            
            # ä» Vector Store åŠ è½½ç´¢å¼• (å¦‚æœé›†åˆä¸ºç©ºï¼Œè¿™ä¼šåˆ›å»ºä¸€ä¸ªç©ºç´¢å¼•)
            index = VectorStoreIndex.from_vector_store(
                vector_store,
                storage_context=storage_context,
                embed_model=self.embed_model
            )
            
            # ç¼“å­˜
            self._indices[collection_name] = index
            return index
            
        except Exception as e:
            print(f"è·å–ç´¢å¼•å¤±è´¥ [{collection_name}]: {e}")
            raise

    def add_document(
        self, 
        doc_id: str, 
        content: str, 
        metadata: Optional[Dict[str, Any]] = None,
        course_id: Optional[str] = None
    ) -> bool:
        if not self.available:
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡æ–‡æ¡£æ·»åŠ ")
            return False
        """
        æ·»åŠ æ–‡æ¡£åˆ° LlamaIndex
        """
        try:
            if metadata is None:
                metadata = {}
            
            # ç¡®ä¿å…ƒæ•°æ®ä¸­åŒ…å«ä¾¿äºå¼•ç”¨çš„å­—æ®µ
            metadata['doc_id'] = doc_id
            metadata['indexed_at'] = datetime.now().isoformat()
            
            # åˆ›å»º LlamaIndex æ–‡æ¡£å¯¹è±¡
            doc = Document(
                text=content,
                metadata=metadata,
                id_=doc_id
            )
            
            # è·å–ç´¢å¼•å¹¶æ’å…¥
            index = self.get_index(course_id)
            index.insert(doc)
            
            print(f"æ–‡æ¡£å·²æ·»åŠ : {doc_id} (Course: {course_id})")
            return True
            
        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False

    def search_similar(
        self, 
        query: str, 
        n_results: int = 5,
        filter_metadata: Optional[Dict[str, Any]] = None,
        course_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        if not self.available:
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
            return []
        """
        åŸç”Ÿæ£€ç´¢ (Retriever æ¨¡å¼)ï¼Œä¸ç»è¿‡ LLM ç”Ÿæˆ
        ç”¨äºä¿æŒå‘åå…¼å®¹æ€§
        """
        try:
            index = self.get_index(course_id)
            
            # é…ç½® Retriever
            # æ³¨æ„ï¼šLlamaIndex çš„ vector_store_kwargs å¯ä»¥ä¼  filter
            vector_store_kwargs = {}
            if filter_metadata:
                vector_store_kwargs["where"] = filter_metadata

            retriever = index.as_retriever(
                similarity_top_k=n_results,
                vector_store_kwargs=vector_store_kwargs
            )
            
            nodes = retriever.retrieve(query)
            
            results = []
            for node in nodes:
                results.append({
                    "id": node.node_id,
                    "content": node.text,
                    "metadata": node.metadata,
                    "similarity": node.score or 0.0
                })
                
            return results
            
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")
            return []

    def get_citation_query_engine(self, course_id: Optional[str] = None, similarity_top_k: int = 3):
        if not self.available:
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæŸ¥è¯¢å¼•æ“")
            return None
        """
        è·å–å¸¦å¼•ç”¨åŠŸèƒ½çš„æŸ¥è¯¢å¼•æ“
        è¿™æ˜¯ LlamaIndex çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€
        """
        index = self.get_index(course_id)
        
        # åˆ›å»º CitationQueryEngine
        # å®ƒä¼šè‡ªåŠ¨æ£€ç´¢ï¼Œå¹¶è®© LLM ç”Ÿæˆå¸¦æœ‰å¼•ç”¨çš„å›ç­”
        query_engine = CitationQueryEngine.from_args(
            index,
            similarity_top_k=similarity_top_k,
            citation_chunk_size=512, # å¼•ç”¨å—çš„å¤§å°
        )
        return query_engine
        
    def delete_document(self, doc_id: str, course_id: Optional[str] = None) -> bool:
        if not self.available:
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡æ–‡æ¡£åˆ é™¤")
            return False
        """åˆ é™¤æ–‡æ¡£"""
        try:
            index = self.get_index(course_id)
            index.delete_ref_doc(doc_id, delete_from_docstore=True)
            return True
        except Exception as e:
            print(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            # å¦‚æœ LlamaIndex åˆ é™¤å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ—§æ•°æ®ï¼‰ï¼Œå°è¯•ç›´æ¥æ“ä½œ Chroma
            try:
                if course_id:
                    c_name = f"course_{course_id.replace('-', '_')}"
                else:
                    c_name = self.survey_collection_name
                self.client.get_collection(c_name).delete(ids=[doc_id])
                return True
            except Exception as e2:
                print(f"Chromaç›´æ¥åˆ é™¤ä¹Ÿå¤±è´¥: {e2}")
                return False

    def delete_course_collection(self, course_id: str) -> bool:
        if not self.available:
            print("âš ï¸  å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡è¯¾ç¨‹é›†åˆåˆ é™¤")
            return False
        """åˆ é™¤è¯¾ç¨‹é›†åˆ"""
        try:
            collection_name = f"course_{course_id.replace('-', '_')}"
            self.client.delete_collection(name=collection_name)
            
            if collection_name in self._indices:
                del self._indices[collection_name]
                
            print(f"âœ… å·²åˆ é™¤è¯¾ç¨‹çŸ¥è¯†åº“é›†åˆ: {collection_name}")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤è¯¾ç¨‹é›†åˆå¤±è´¥: {e}")
            return False

# å…¨å±€å•ä¾‹
# vector_db = VectorDBService() 
# æ³¨æ„ï¼šæˆ‘ä»¬ä¸åœ¨æ¨¡å—çº§åˆ«å®ä¾‹åŒ–ï¼Œè€Œæ˜¯åœ¨ä½¿ç”¨æ—¶å®ä¾‹åŒ–ï¼Œé¿å…å¯¼å…¥æ—¶çš„å‰¯ä½œç”¨

def get_vector_db():
    """è·å–å‘é‡æ•°æ®åº“æœåŠ¡å®ä¾‹"""
    if not LLAMA_INDEX_AVAILABLE:
        print("âš ï¸  LlamaIndex ä¸å¯ç”¨ï¼Œæ— æ³•æä¾›å‘é‡æ•°æ®åº“æœåŠ¡")
        return None
    return VectorDBService()
