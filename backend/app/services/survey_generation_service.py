"""é—®å·AIç”ŸæˆæœåŠ¡ - é›†æˆDeepSeek APIå’ŒæŠ€èƒ½æ³¨å…¥"""

import json
import re
from typing import Dict, List, Optional, Any
from openai import OpenAI
from pathlib import Path
from sqlalchemy.orm import Session
from datetime import datetime
import uuid

from app.services.skill_loader import SkillLoader, Skill
from app.services.vector_db_service import VectorDBService
from app.models.survey import Survey, Question


class SurveyGenerationService:
    """é—®å·AIç”ŸæˆæœåŠ¡ - å‚è€ƒchat-skillsæ¶æ„"""

    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        # DeepSeek APIé…ç½®
        self.api_key = "sk-11fe906e92c84e0f95c9f04ae6ed1565"
        self.base_url = "https://api.deepseek.com/v1"
        self.model_name = "deepseek-chat"
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹DeepSeekï¼‰
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # åŠ è½½æŠ€èƒ½
        self.skill_loader = SkillLoader()
        self.skill_loader.load_skills()
        
        # å‘é‡æ•°æ®åº“æœåŠ¡ï¼ˆç”¨äºçŸ¥è¯†åº“æŸ¥è¯¢ï¼‰
        self.vector_service = VectorDBService()

    def generate_survey_ai(
        self, 
        description: str,
        question_count: int = 10,
        include_types: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        AIç”Ÿæˆé—®å· - çº¯AIæ·±åº¦æ€è€ƒï¼Œä¸è°ƒç”¨çŸ¥è¯†åº“
        
        Args:
            description: ç”¨æˆ·æè¿°
            question_count: é¢˜ç›®æ•°é‡
            include_types: åŒ…å«çš„é¢˜å‹ ["choice", "judge", "essay"]
            
        Returns:
            ç”Ÿæˆçš„é—®å·æ•°æ®
        """
        print("=" * 70)
        print("ğŸ¤– AIç”Ÿæˆæ¨¡å¼ - çº¯æ·±åº¦æ€è€ƒï¼Œä¸è°ƒç”¨çŸ¥è¯†åº“")
        print(f"ğŸ“ æè¿°: {description}")
        print(f"ğŸ“Š é¢˜ç›®æ•°é‡: {question_count}")
        print(f"ğŸ“‹ é¢˜å‹è¦æ±‚: {include_types or 'å…¨éƒ¨é¢˜å‹'}")
        print("=" * 70)
        
        # è·å–AIç”ŸæˆæŠ€èƒ½
        skill = self.skill_loader.get_skill_by_name("AIé—®å·ç”Ÿæˆå™¨")
        
        if not skill:
            raise ValueError("æœªæ‰¾åˆ°AIé—®å·ç”ŸæˆæŠ€èƒ½æ¨¡æ¿")
        
        # æ„å»ºç”¨æˆ·æç¤º
        user_prompt = self._build_ai_generation_prompt(
            description, 
            question_count, 
            include_types
        )
        
        print(f"ğŸ’¬ ç”¨æˆ·æç¤º:\n{user_prompt}\n")
        
        # æ³¨å…¥æŠ€èƒ½å¹¶è°ƒç”¨AI
        response_text = self._call_llm_with_skill(skill, user_prompt)
        
        # è§£æJSONå“åº”
        survey_data = self._parse_json_response(response_text)
        
        # éªŒè¯é¢˜å‹æ˜¯å¦ç¬¦åˆè¦æ±‚
        if include_types:
            self._validate_question_types(survey_data, include_types)
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(survey_data.get('questions', []))} é“é¢˜ç›®")
        print("=" * 70)
        
        return survey_data

    def generate_survey_knowledge_based(
        self,
        description: str,
        course_id: Optional[str] = None,
        question_count: int = 10,
        include_types: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        åŸºäºçŸ¥è¯†åº“ç”Ÿæˆé—®å·ï¼ˆä¼˜å…ˆæ£€ç´¢æ¨¡å¼ï¼‰
        
        ç”Ÿæˆç­–ç•¥ï¼š
        1. å¿…é¡»å…ˆæ£€ç´¢çŸ¥è¯†åº“ï¼ˆå¦‚æœæŒ‡å®šäº†course_idåˆ™æ£€ç´¢è¯¥è¯¾ç¨‹ï¼Œå¦åˆ™æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“ï¼‰
        2. å¦‚æœæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ï¼Œä¼˜å…ˆåŸºäºçŸ¥è¯†åº“ç”Ÿæˆ
        3. åªæœ‰åœ¨çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³å†…å®¹æ—¶ï¼Œæ‰åŸºäºAIæ·±åº¦æ€è€ƒç”Ÿæˆ
        
        Args:
            description: ç”¨æˆ·æè¿°
            course_id: è¯¾ç¨‹IDï¼ˆUUIDå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼Œä¸ä¼ åˆ™åœ¨æ‰€æœ‰çŸ¥è¯†åº“ä¸­æ£€ç´¢ï¼‰
            question_count: é¢˜ç›®æ•°é‡
            include_types: åŒ…å«çš„é¢˜å‹
            
        Returns:
            ç”Ÿæˆçš„é—®å·æ•°æ®
        """
        print("=" * 70)
        print("ğŸ“š çŸ¥è¯†åº“ç”Ÿæˆæ¨¡å¼ - ä¼˜å…ˆæ£€ç´¢çŸ¥è¯†åº“")
        print(f"ğŸ“ æè¿°: {description}")
        print(f"ğŸ“Š é¢˜ç›®æ•°é‡: {question_count}")
        print(f"ğŸ“‹ é¢˜å‹è¦æ±‚: {include_types or 'å…¨éƒ¨é¢˜å‹'}")
        print(f"ğŸ“š è¯¾ç¨‹ID: {course_id if course_id else 'æ‰€æœ‰è¯¾ç¨‹ï¼ˆå…¨å±€æ£€ç´¢ï¼‰'}")
        print("=" * 70)
        
        # 1. å¿…é¡»å…ˆæ£€ç´¢çŸ¥è¯†åº“
        print("ğŸ” æ­¥éª¤1: å¼€å§‹æ£€ç´¢çŸ¥è¯†åº“...")
        knowledge_context, has_knowledge = self._retrieve_knowledge_smart(description, course_id)
        
        if has_knowledge:
            print(f"âœ… æ£€ç´¢æˆåŠŸï¼æ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œä¼˜å…ˆåŸºäºçŸ¥è¯†åº“ç”Ÿæˆ")
        else:
            print(f"âš ï¸  çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œå°†åŸºäºAIæ·±åº¦æ€è€ƒç”Ÿæˆ")
        
        # 2. è·å–çŸ¥è¯†åº“ç”ŸæˆæŠ€èƒ½
        skill = self.skill_loader.get_skill_by_name("åŸºäºçŸ¥è¯†åº“çš„é—®å·ç”Ÿæˆå™¨")
        
        if not skill:
            raise ValueError("æœªæ‰¾åˆ°çŸ¥è¯†åº“é—®å·ç”ŸæˆæŠ€èƒ½æ¨¡æ¿")
        
        # 3. æ„å»ºæç¤ºï¼ˆæ ¹æ®æ˜¯å¦æœ‰çŸ¥è¯†é‡‡ç”¨ä¸åŒç­–ç•¥ï¼‰
        user_prompt = self._build_kb_generation_prompt_smart(
            description,
            knowledge_context,
            question_count,
            include_types,
            has_knowledge
        )
        
        print(f"\nğŸ’¬ ç”Ÿæˆç­–ç•¥: {'[çŸ¥è¯†åº“ä¼˜å…ˆ]' if has_knowledge else '[AIæ·±åº¦æ€è€ƒ]'}\n")
        
        # 4. æ³¨å…¥æŠ€èƒ½å¹¶è°ƒç”¨AI
        response_text = self._call_llm_with_skill(skill, user_prompt)
        
        # 5. è§£æJSONå“åº”
        survey_data = self._parse_json_response(response_text)
        
        # 6. éªŒè¯é¢˜å‹æ˜¯å¦ç¬¦åˆè¦æ±‚
        if include_types:
            self._validate_question_types(survey_data, include_types)
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(survey_data.get('questions', []))} é“é¢˜ç›®")
        print(f"ğŸ“š ç”Ÿæˆæ¨¡å¼: {'[çŸ¥è¯†åº“ä¼˜å…ˆ]' if has_knowledge else '[AIæ·±åº¦æ€è€ƒ]'}")
        print("=" * 70)
        
        return survey_data

    def _retrieve_knowledge_smart(
        self, 
        query: str, 
        course_id: Optional[str] = None, 
        top_k: int = 8
    ) -> tuple[str, bool]:
        """
        æ™ºèƒ½æ£€ç´¢çŸ¥è¯†åº“
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            course_id: è¯¾ç¨‹IDï¼ˆUUIDå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼Œä¸ä¼ åˆ™æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            (knowledge_context, has_knowledge): çŸ¥è¯†å†…å®¹å’Œæ˜¯å¦æœ‰çŸ¥è¯†
        """
        try:
            print(f"   â¡ï¸ æ£€ç´¢æŸ¥è¯¢: {query[:50]}...")
            print(f"   â¡ï¸ è¯¾ç¨‹ID: {course_id if course_id else 'æ‰€æœ‰è¯¾ç¨‹ï¼ˆå…¨å±€æ£€ç´¢ï¼‰'}")
            print(f"   â¡ï¸ æ£€ç´¢æ•°é‡: top_{top_k}")
            
            # ä½¿ç”¨å‘é‡æ•°æ®åº“æœåŠ¡æŸ¥è¯¢
            # course_idå·²ç»æ˜¯UUIDå­—ç¬¦ä¸²æˆ–None
            results = self.vector_service.search_similar(
                query=query,
                course_id=course_id,
                n_results=top_k
            )
            
            if not results:
                print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³çŸ¥è¯†")
                return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚", False
            
            print(f"   âœ… æ£€ç´¢åˆ° {len(results)} æ¡ç›¸å…³çŸ¥è¯†")
            
            # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
            knowledge_parts = []
            knowledge_parts.append(f"æ£€ç´¢åˆ° {len(results)} æ¡ç›¸å…³çŸ¥è¯†ï¼š\n")
            
            for idx, result in enumerate(results, 1):
                content = result.get('content', '')
                metadata = result.get('metadata', {}) or {}  # ç¡®ä¿metadataä¸æ˜¯None
                similarity = result.get('similarity', 0)
                
                # è·å–æ¥æºä¿¡æ¯ï¼Œå¤„ç†å„ç§å¯èƒ½çš„é”®å
                source = (
                    metadata.get('source') or 
                    metadata.get('filename') or 
                    metadata.get('file_name') or 
                    metadata.get('document_name') or 
                    'æœªçŸ¥æ¥æº'
                )
                
                knowledge_parts.append(f"[çŸ¥è¯†ç‰‡æ®µ{idx}]")
                knowledge_parts.append(f"ç›¸å…³åº¦: {similarity:.1%}")
                knowledge_parts.append(f"æ¥æº: {source}")
                knowledge_parts.append(f"å†…å®¹: {content[:300]}...")  # å¢åŠ é•¿åº¦ä»200åˆ°300
                knowledge_parts.append("")
                
                # æ‰“å°åˆ°æ§åˆ¶å°
                print(f"   ğŸ“š ç‰‡æ®µ{idx}: {source} (ç›¸å…³åº¦: {similarity:.1%})")
            
            return "\n".join(knowledge_parts), True
            
        except Exception as e:
            print(f"   âŒ çŸ¥è¯†æ£€ç´¢é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return f"çŸ¥è¯†åº“æ£€ç´¢é‡åˆ°é—®é¢˜ï¼Œå°†åŸºäºä¸»é¢˜æ·±åº¦æ€è€ƒå‡ºé¢˜ã€‚", False

    def _build_ai_generation_prompt(
        self,
        description: str,
        question_count: int,
        include_types: Optional[List[str]]
    ) -> str:
        """æ„å»ºAIç”Ÿæˆçš„ç”¨æˆ·æç¤º"""
        prompt_parts = [
            f"è¯·æ ¹æ®ä»¥ä¸‹æè¿°ç”Ÿæˆä¸€ä»½é—®å·ï¼š",
            f"",
            f"æè¿°: {description}",
            f"é¢˜ç›®æ•°é‡: {question_count}é¢˜",
        ]
        
        if include_types:
            types_map = {
                "choice": "é€‰æ‹©é¢˜",
                "judge": "åˆ¤æ–­é¢˜",
                "essay": "é—®ç­”é¢˜"
            }
            types_str = "ã€".join([types_map.get(t, t) for t in include_types])
            prompt_parts.append(f"é¢˜å‹è¦æ±‚: ã€ä¸¥æ ¼é™åˆ¶ã€‘åªèƒ½ç”Ÿæˆ{types_str}ï¼Œä¸èƒ½ç”Ÿæˆå…¶ä»–é¢˜å‹")
            prompt_parts.append(f"âš ï¸ é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼éµå®ˆé¢˜å‹é™åˆ¶ï¼Œç”Ÿæˆçš„{question_count}é“é¢˜ç›®å¿…é¡»å…¨éƒ¨æ˜¯æŒ‡å®šçš„é¢˜å‹")
        else:
            prompt_parts.append(f"é¢˜å‹è¦æ±‚: é€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ã€é—®ç­”é¢˜åˆç†åˆ†å¸ƒ")
        
        prompt_parts.extend([
            f"",
            f"ã€å¿…é¡»ä¸¥æ ¼éµå®ˆçš„æ ¼å¼è¦æ±‚ã€‘ï¼š",
            f"1. ä¸¥æ ¼æŒ‰ç…§æŠ€èƒ½æ¨¡æ¿ä¸­çš„JSONæ ¼å¼è¾“å‡º",
            f"2. é€‰æ‹©é¢˜(choice)å¿…é¡»æœ‰4ä¸ªé€‰é¡¹: [\"A. é€‰é¡¹1\", \"B. é€‰é¡¹2\", \"C. é€‰é¡¹3\", \"D. é€‰é¡¹4\"]",
            f"3. åˆ¤æ–­é¢˜(judge)å¿…é¡»æœ‰2ä¸ªé€‰é¡¹: [\"æ­£ç¡®\", \"é”™è¯¯\"]",
            f"4. é—®ç­”é¢˜(essay)çš„optionså¿…é¡»æ˜¯ç©ºæ•°ç»„: []",
            f"5. ç¡®ä¿æ‰€æœ‰ç­”æ¡ˆå‡†ç¡®æ— è¯¯",
            f"6. æ¯é¢˜å¿…é¡»æœ‰è¯¦ç»†è§£æï¼ˆè‡³å°‘50å­—ï¼‰",
            f"7. åˆ†æ•°åˆ†é…åˆç†ï¼Œæ€»åˆ†æ¥è¿‘100åˆ†",
            f"8. åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—æˆ–markdownæ ‡è®°",
            f"",
            f"âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼šé€‰æ‹©é¢˜å’Œåˆ¤æ–­é¢˜çš„optionså­—æ®µæ˜¯å¿…å¡«é¡¹ï¼Œç»å¯¹ä¸èƒ½ä¸ºç©ºï¼",
        ])
        
        return "\n".join(prompt_parts)

    def _build_kb_generation_prompt_smart(
        self,
        description: str,
        knowledge_context: str,
        question_count: int,
        include_types: Optional[List[str]],
        has_knowledge: bool
    ) -> str:
        """æ„å»ºåŸºäºçŸ¥è¯†åº“ç”Ÿæˆçš„ç”¨æˆ·æç¤ºï¼ˆæ™ºèƒ½æ¨¡å¼ï¼‰"""
        prompt_parts = [
            f"è¯·åŸºäºçŸ¥è¯†åº“å†…å®¹å’Œæ·±åº¦æ€è€ƒç”Ÿæˆé—®å·ï¼š",
            f"",
            f"ç”¨æˆ·éœ€æ±‚: {description}",
            f"é¢˜ç›®æ•°é‡: {question_count}é¢˜",
        ]
        
        if include_types:
            types_map = {
                "choice": "é€‰æ‹©é¢˜",
                "judge": "åˆ¤æ–­é¢˜",
                "essay": "é—®ç­”é¢˜"
            }
            types_str = "ã€".join([types_map.get(t, t) for t in include_types])
            prompt_parts.append(f"é¢˜å‹è¦æ±‚: ã€ä¸¥æ ¼é™åˆ¶ã€‘åªèƒ½ç”Ÿæˆ{types_str}ï¼Œä¸èƒ½ç”Ÿæˆå…¶ä»–é¢˜å‹")
            prompt_parts.append(f"âš ï¸ é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼éµå®ˆé¢˜å‹é™åˆ¶ï¼Œç”Ÿæˆçš„{question_count}é“é¢˜ç›®å¿…é¡»å…¨éƒ¨æ˜¯æŒ‡å®šçš„é¢˜å‹")
        else:
            prompt_parts.append(f"é¢˜å‹è¦æ±‚: é€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ã€é—®ç­”é¢˜åˆç†åˆ†å¸ƒ")
        
        prompt_parts.extend([
            f"",
            f"=" * 60,
            f"çŸ¥è¯†åº“æ£€ç´¢å†…å®¹ï¼š",
            f"=" * 60,
            knowledge_context,
            f"=" * 60,
            f"",
        ])
        
        if has_knowledge:
            # æœ‰çŸ¥è¯†åº“å†…å®¹ï¼šä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“
            prompt_parts.extend([
                f"ğŸ“š ç”Ÿæˆç­–ç•¥ï¼ˆçŸ¥è¯†åº“ä¼˜å…ˆæ¨¡å¼ï¼‰ï¼š",
                f"",
                f"1. **åŸºäºçŸ¥è¯†åº“ç”Ÿæˆ**ï¼š",
                f"   - ä»”ç»†é˜…è¯»ä¸Šè¿°æ£€ç´¢åˆ°çš„çŸ¥è¯†å†…å®¹",
                f"   - ä¼˜å…ˆä»çŸ¥è¯†åº“ä¸­æå–é¢˜ç›®å’Œç­”æ¡ˆ",
                f"   - æ¯é¢˜å¿…é¡»æ ‡æ³¨knowledge_sourceå­—æ®µ",
                f"   - ç¡®ä¿é¢˜ç›®ä¸çŸ¥è¯†åº“å†…å®¹ç›´æ¥ç›¸å…³",
                f"",
                f"2. **è´¨é‡ä¿è¯**ï¼š",
                f"   - æ‰€æœ‰ç­”æ¡ˆå¿…é¡»å‡†ç¡®æ— è¯¯",
                f"   - æœ‰çŸ¥è¯†åº“æ”¯æ’‘çš„é¢˜ç›®ï¼Œæ ‡æ³¨å…·ä½“æ¥æº",
                f"   - è§£æå¿…é¡»å¼•ç”¨çŸ¥è¯†åº“ä¸­çš„ç›¸å…³å†…å®¹",
                f"",
                f"3. **æ ‡æ³¨è§„èŒƒ**ï¼š",
                f"   - ç›´æ¥æ¥è‡ªçŸ¥è¯†åº“ï¼š\"æ–‡æ¡£å - å…·ä½“ç« èŠ‚\"",
                f"   - ä¾‹å¦‚ï¼šknowledge_source: \"æ“ä½œç³»ç»Ÿæ•™ç¨‹ - ç¬¬3ç« è¿›ç¨‹ç®¡ç†\"",
            ])
        else:
            # æ²¡æœ‰çŸ¥è¯†åº“å†…å®¹ï¼šåŸºäºAIæ·±åº¦æ€è€ƒ
            prompt_parts.extend([
                f"ğŸ§  ç”Ÿæˆç­–ç•¥ï¼ˆAIæ·±åº¦æ€è€ƒæ¨¡å¼ï¼‰ï¼š",
                f"",
                f"âš ï¸ **æ³¨æ„**ï¼šçŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¯·åŸºäºä¸»é¢˜æ·±åº¦æ€è€ƒç”Ÿæˆé¢˜ç›®ã€‚",
                f"",
                f"1. **æ·±åº¦æ€è€ƒç”Ÿæˆ**ï¼š",
                f"   - åŸºäºç”¨æˆ·éœ€æ±‚ä¸­çš„ä¸»é¢˜å’Œå…³é”®è¯",
                f"   - è°ƒç”¨ä½ çš„çŸ¥è¯†å’Œé€»è¾‘æ¨ç†èƒ½åŠ›",
                f"   - ç”Ÿæˆé«˜è´¨é‡ã€ç¬¦åˆä¸»é¢˜çš„é¢˜ç›®",
                f"",
                f"2. **è´¨é‡ä¿è¯**ï¼š",
                f"   - ç¡®ä¿ç­”æ¡ˆ100%å‡†ç¡®",
                f"   - æä¾›è¯¦ç»†çš„è§£æå’Œæ¨ç†è¿‡ç¨‹",
                f"   - é¢˜ç›®éš¾åº¦åˆé€‚ï¼Œç¬¦åˆæ•™å­¦è¦æ±‚",
                f"",
                f"3. **æ ‡æ³¨è§„èŒƒ**ï¼š",
                f"   - knowledge_source: \"AIæ·±åº¦æ€è€ƒ - [ä¸»é¢˜]\"",
                f"   - ä¾‹å¦‚ï¼šknowledge_source: \"AIæ·±åº¦æ€è€ƒ - æ“ä½œç³»ç»Ÿè¿›ç¨‹ç®¡ç†\"",
            ])
        
        prompt_parts.extend([
            f"",
            f"=" * 60,
            f"ğŸ“‹ è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š",
            f"",
            f"1. ä¸¥æ ¼æŒ‰ç…§æŠ€èƒ½æ¨¡æ¿ä¸­çš„JSONæ ¼å¼è¾“å‡º",
            f"2. é€‰æ‹©é¢˜(choice)å¿…é¡»æœ‰4ä¸ªé€‰é¡¹: [\"A. é€‰é¡¹1\", \"B. é€‰é¡¹2\", \"C. é€‰é¡¹3\", \"D. é€‰é¡¹4\"]",
            f"3. åˆ¤æ–­é¢˜(judge)å¿…é¡»æœ‰2ä¸ªé€‰é¡¹: [\"æ­£ç¡®\", \"é”™è¯¯\"]",
            f"4. é—®ç­”é¢˜(essay)çš„optionså¿…é¡»æ˜¯ç©ºæ•°ç»„: []",
            f"5. ç¡®ä¿æ‰€æœ‰ç­”æ¡ˆå‡†ç¡®æ— è¯¯",
            f"6. æ¯é¢˜å¿…é¡»æœ‰è¯¦ç»†è§£æï¼ˆâ‰¥50å­—ç¬¦ï¼‰",
            f"7. åˆ†æ•°åˆ†é…åˆç†ï¼Œæ€»åˆ†æ¥è¿‘100åˆ†",
            f"8. æ¯é¢˜å¿…é¡»æ ‡æ³¨knowledge_source",
            f"9. åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—æˆ–markdownæ ‡è®°",
            f"",
            f"âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼šé€‰æ‹©é¢˜å’Œåˆ¤æ–­é¢˜çš„optionså­—æ®µæ˜¯å¿…å¡«é¡¹ï¼Œç»å¯¹ä¸èƒ½ä¸ºç©ºï¼",
        ])
        
        return "\n".join(prompt_parts)

    def _call_llm_with_skill(self, skill: Skill, user_prompt: str) -> str:
        """
        è°ƒç”¨LLMå¹¶æ³¨å…¥æŠ€èƒ½ - å‚è€ƒchat-skillsçš„æ³¨å…¥æ–¹å¼
        
        Args:
            skill: æŠ€èƒ½å¯¹è±¡
            user_prompt: ç”¨æˆ·æç¤º
            
        Returns:
            AIå“åº”æ–‡æœ¬
        """
        # æ„å»ºç³»ç»Ÿæç¤ºï¼ˆæ³¨å…¥æŠ€èƒ½ï¼‰
        system_prompt = self._build_system_prompt_with_skill(skill)
        
        # è°ƒç”¨OpenAIå…¼å®¹API
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"è°ƒç”¨DeepSeek APIå¤±è´¥: {str(e)}")

    def _build_system_prompt_with_skill(self, skill: Skill) -> str:
        """
        æ„å»ºåŒ…å«æŠ€èƒ½æ³¨å…¥çš„ç³»ç»Ÿæç¤º - å‚è€ƒchat-skills
        
        Args:
            skill: æŠ€èƒ½å¯¹è±¡
            
        Returns:
            å®Œæ•´çš„ç³»ç»Ÿæç¤º
        """
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®å·ç”ŸæˆåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆé«˜è´¨é‡çš„é—®å·ã€‚

å½“æŠ€èƒ½æŒ‡å¯¼è¢«æä¾›æ—¶ï¼š
- ä¸¥æ ¼éµå¾ªæŠ€èƒ½ä¸­å®šä¹‰çš„æ ¼å¼å’Œè§„èŒƒ
- ç¡®ä¿è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§
- åªè¾“å‡ºè¦æ±‚çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹
- æ‰€æœ‰ç­”æ¡ˆå¿…é¡»å‡†ç¡®ï¼Œè§£æå¿…é¡»è¯¦ç»†
"""
        
        # æ³¨å…¥æŠ€èƒ½å†…å®¹
        parts = [
            base_prompt,
            "\n" + "=" * 60,
            "æŠ€èƒ½æŒ‡å¯¼å†…å®¹ï¼ˆå¿…é¡»éµå¾ªï¼‰",
            "=" * 60,
            f"\næŠ€èƒ½åç§°: {skill.name}\n",
            skill.content,
            "\n" + "=" * 60,
            "æŠ€èƒ½æŒ‡å¯¼å†…å®¹ç»“æŸ",
            "=" * 60,
            "\né‡è¦æé†’ï¼š",
            "- ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æŠ€èƒ½æ¨¡æ¿ç”Ÿæˆå†…å®¹",
            "- åªè¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦æœ‰markdownä»£ç å—æ ‡è®°",
            "- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®å¯è§£æ",
            "- æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½è¦å¡«å†™å®Œæ•´"
        ]
        
        return "\n".join(parts)

    def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
        """
        è§£æAIè¿”å›çš„JSONå“åº” - å¤„ç†å„ç§æ ¼å¼
        
        Args:
            response_text: AIå“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å­—å…¸
        """
        # æ¸…ç†å“åº”æ–‡æœ¬
        cleaned_text = response_text.strip()
        
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        if cleaned_text.startswith("```"):
            lines = cleaned_text.split("\n")
            # ç§»é™¤å¼€å¤´çš„```jsonæˆ–```
            if lines[0].startswith("```"):
                lines = lines[1:]
            # ç§»é™¤ç»“å°¾çš„```
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            cleaned_text = "\n".join(lines).strip()
        
        # å°è¯•è§£æJSON
        try:
            data = json.loads(cleaned_text)
        except json.JSONDecodeError as e:
            # å°è¯•æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
            if json_match:
                try:
                    data = json.loads(json_match.group())
                except:
                    raise ValueError(f"æ— æ³•è§£æAIè¿”å›çš„JSON: {str(e)}\nåŸå§‹å“åº”: {response_text[:500]}")
            else:
                raise ValueError(f"å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSON: {response_text[:500]}")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ["survey_title", "description", "questions"]
        for field in required_fields:
            if field not in data:
                raise ValueError(f"ç”Ÿæˆçš„é—®å·ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯é¢˜ç›®æ ¼å¼
        if not isinstance(data["questions"], list) or len(data["questions"]) == 0:
            raise ValueError("ç”Ÿæˆçš„é—®å·æ²¡æœ‰é¢˜ç›®")
        
        # ğŸ”§ ä¿®å¤é€‰æ‹©é¢˜å’Œåˆ¤æ–­é¢˜çš„options - ç¡®ä¿ä¸€å®šæœ‰é€‰é¡¹
        for idx, question in enumerate(data["questions"], 1):
            q_type = question.get("question_type")
            options = question.get("options", [])
            
            # é€‰æ‹©é¢˜å¿…é¡»æœ‰4ä¸ªé€‰é¡¹
            if q_type == "choice":
                if not options or len(options) < 4:
                    print(f"âš ï¸  è­¦å‘Š: ç¬¬{idx}é¢˜ï¼ˆé€‰æ‹©é¢˜ï¼‰ç¼ºå°‘é€‰é¡¹ï¼Œè‡ªåŠ¨è¡¥å……æ ‡å‡†é€‰é¡¹")
                    question["options"] = ["A. é€‰é¡¹A", "B. é€‰é¡¹B", "C. é€‰é¡¹C", "D. é€‰é¡¹D"]
                elif len(options) > 4:
                    # å¦‚æœè¶…è¿‡4ä¸ªï¼Œåªä¿ç•™å‰4ä¸ª
                    question["options"] = options[:4]
            
            # åˆ¤æ–­é¢˜å¿…é¡»æœ‰2ä¸ªé€‰é¡¹
            elif q_type == "judge":
                if not options or len(options) < 2:
                    print(f"âš ï¸  è­¦å‘Š: ç¬¬{idx}é¢˜ï¼ˆåˆ¤æ–­é¢˜ï¼‰ç¼ºå°‘é€‰é¡¹ï¼Œè‡ªåŠ¨è¡¥å……æ­£ç¡®/é”™è¯¯é€‰é¡¹")
                    question["options"] = ["æ­£ç¡®", "é”™è¯¯"]
                elif options != ["æ­£ç¡®", "é”™è¯¯"]:
                    # è§„èŒƒåŒ–åˆ¤æ–­é¢˜é€‰é¡¹
                    question["options"] = ["æ­£ç¡®", "é”™è¯¯"]
            
            # é—®ç­”é¢˜ç¡®ä¿optionsæ˜¯ç©ºæ•°ç»„
            elif q_type == "essay":
                question["options"] = []
        
        return data

    def validate_survey_data(self, survey_data: Dict[str, Any]) -> bool:
        """
        éªŒè¯é—®å·æ•°æ®æ ¼å¼
        
        Args:
            survey_data: é—®å·æ•°æ®
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬å­—æ®µ
            if not all(key in survey_data for key in ["survey_title", "description", "questions"]):
                return False
            
            # æ£€æŸ¥æ¯é“é¢˜
            for question in survey_data["questions"]:
                required = ["question_type", "question_text", "correct_answer", "score", "explanation"]
                if not all(key in question for key in required):
                    return False
                
                # æ£€æŸ¥é¢˜å‹
                if question["question_type"] not in ["choice", "judge", "essay"]:
                    return False
                
                # é€‰æ‹©é¢˜å’Œåˆ¤æ–­é¢˜éœ€è¦options
                if question["question_type"] in ["choice", "judge"]:
                    if "options" not in question or not question["options"]:
                        return False
            
            return True
            
        except Exception:
            return False

    def _validate_question_types(
        self, 
        survey_data: Dict[str, Any], 
        expected_types: List[str]
    ) -> None:
        """
        éªŒè¯ç”Ÿæˆçš„é¢˜ç›®æ˜¯å¦ç¬¦åˆé¢˜å‹è¦æ±‚
        
        Args:
            survey_data: é—®å·æ•°æ®
            expected_types: æœŸæœ›çš„é¢˜å‹åˆ—è¡¨
            
        Raises:
            ValueError: å¦‚æœé¢˜å‹ä¸ç¬¦åˆè¦æ±‚
        """
        questions = survey_data.get('questions', [])
        
        for idx, question in enumerate(questions, 1):
            q_type = question.get('question_type')
            
            if q_type not in expected_types:
                # é¢˜å‹ä¸ç¬¦åˆè¦æ±‚
                types_map = {
                    "choice": "é€‰æ‹©é¢˜",
                    "judge": "åˆ¤æ–­é¢˜",
                    "essay": "é—®ç­”é¢˜"
                }
                expected_str = "ã€".join([types_map.get(t, t) for t in expected_types])
                actual_str = types_map.get(q_type, q_type)
                
                error_msg = (
                    f"âŒ é¢˜å‹éªŒè¯å¤±è´¥ï¼\n"
                    f"   ç¬¬{idx}é¢˜æ˜¯{actual_str}ï¼Œä½†åªå…è®¸ç”Ÿæˆï¼š{expected_str}\n"
                    f"   é¢˜ç›®ï¼š{question.get('question_text', '')[:50]}...\n"
                    f"   è¯·ç¡®ä¿æ‰€æœ‰é¢˜ç›®éƒ½æ˜¯æŒ‡å®šçš„é¢˜å‹ã€‚"
                )
                print(error_msg)
                raise ValueError(error_msg)
        
        print(f"âœ… é¢˜å‹éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰ {len(questions)} é“é¢˜ç›®éƒ½ç¬¦åˆè¦æ±‚")

    def save_to_database(
        self,
        survey_data: Dict[str, Any],
        teacher_id: str,
        course_id: Optional[str],
        generation_method: str,
        generation_prompt: str,
        db: Session
    ) -> Survey:
        """
        å°†ç”Ÿæˆçš„é—®å·ä¿å­˜åˆ°æ•°æ®åº“
        
        Args:
            survey_data: ç”Ÿæˆçš„é—®å·æ•°æ®
            teacher_id: æ•™å¸ˆID
            course_id: è¯¾ç¨‹IDï¼ˆå¯é€‰ï¼‰
            generation_method: ç”Ÿæˆæ–¹å¼ ('ai' æˆ– 'knowledge_based')
            generation_prompt: ç”Ÿæˆæç¤ºè¯
            db: æ•°æ®åº“ä¼šè¯
            
        Returns:
            åˆ›å»ºçš„Surveyå¯¹è±¡
        """
        try:
            # åˆ›å»ºé—®å·è®°å½•
            survey = Survey(
                title=survey_data["survey_title"],
                description=survey_data.get("description", ""),
                teacher_id=uuid.UUID(teacher_id),
                course_id=uuid.UUID(course_id) if course_id else None,
                survey_type='exam',  # AIç”Ÿæˆçš„é»˜è®¤ä¸ºè€ƒè¯•ç±»å‹
                generation_method=generation_method,
                generation_prompt=generation_prompt,
                status='draft',  # åˆå§‹çŠ¶æ€ä¸ºè‰ç¨¿
                total_score=self._calculate_total_score(survey_data["questions"]),
                pass_score=60,
                allow_multiple_attempts=False,
                max_attempts=1,
                show_answer=True,  # AIç”Ÿæˆçš„é»˜è®¤æ˜¾ç¤ºç­”æ¡ˆ
                shuffle_questions=False
            )
            
            db.add(survey)
            db.flush()  # è·å–survey_id
            
            # åˆ›å»ºé¢˜ç›®è®°å½•
            for idx, q_data in enumerate(survey_data["questions"], start=1):
                question = Question(
                    survey_id=survey.id,
                    question_type=q_data["question_type"],
                    question_text=q_data["question_text"],
                    question_order=idx,
                    score=float(q_data["score"]),
                    difficulty='medium',  # é»˜è®¤ä¸­ç­‰éš¾åº¦
                    options=q_data.get("options", []),
                    correct_answer=q_data["correct_answer"],
                    answer_explanation=q_data.get("explanation", ""),
                    tags=[],
                    knowledge_points=self._extract_knowledge_points(q_data),
                    is_required=True
                )
                db.add(question)
            
            db.commit()
            db.refresh(survey)
            
            return survey
            
        except Exception as e:
            db.rollback()
            raise Exception(f"ä¿å­˜é—®å·åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")

    def _calculate_total_score(self, questions: List[Dict]) -> int:
        """è®¡ç®—é—®å·æ€»åˆ†"""
        total = sum(float(q.get("score", 0)) for q in questions)
        return int(total)

    def _extract_knowledge_points(self, question_data: Dict) -> List[str]:
        """ä»é¢˜ç›®æ•°æ®ä¸­æå–çŸ¥è¯†ç‚¹"""
        knowledge_points = []
        
        # å¦‚æœæœ‰knowledge_sourceå­—æ®µï¼ˆçŸ¥è¯†åº“ç”Ÿæˆï¼‰
        if "knowledge_source" in question_data:
            knowledge_points.append(question_data["knowledge_source"])
        
        return knowledge_points
