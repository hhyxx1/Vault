#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†PostgreSQLä¸­çš„çœŸå®æ–‡æ¡£å†…å®¹åŒæ­¥åˆ°ChromaDBå‘é‡æ•°æ®åº“
"""

import psycopg2
import sys
import os

# æ·»åŠ appç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

from services.vector_db_service import VectorDBService

DATABASE_URL = "postgresql://postgres:123456@localhost:5432/app_project"

def sync_to_chromadb():
    """å°†PostgreSQLä¸­çš„æ•°æ®åŒæ­¥åˆ°ChromaDB"""
    
    print("=" * 80)
    print("ğŸ”„ åŒæ­¥PostgreSQLæ•°æ®åˆ°ChromaDBå‘é‡æ•°æ®åº“")
    print("=" * 80)
    
    try:
        # è¿æ¥æ•°æ®åº“
        conn = psycopg2.connect(DATABASE_URL)
        cursor = conn.cursor()
        
        # åˆå§‹åŒ–å‘é‡æœåŠ¡
        vector_service = VectorDBService()
        collection = vector_service.course_collection
        
        # 1. æ¸…ç©ºChromaDBæ—§æ•°æ®
        print("\n1ï¸âƒ£ æ¸…ç©ºChromaDBæ—§æ•°æ®...")
        old_count = collection.count()
        print(f"   å½“å‰æ•°æ®: {old_count} ä¸ªå‘é‡")
        
        if old_count > 0:
            # è·å–æ‰€æœ‰IDå¹¶åˆ é™¤
            all_data = collection.get()
            if all_data['ids']:
                collection.delete(ids=all_data['ids'])
                print(f"   âœ… å·²åˆ é™¤ {len(all_data['ids'])} ä¸ªæ—§å‘é‡")
        
        # 2. ä»PostgreSQLè¯»å–çœŸå®æ•°æ®
        print("\n2ï¸âƒ£ ä»PostgreSQLè¯»å–çœŸå®æ–‡æ¡£å†…å®¹...")
        cursor.execute("""
            SELECT 
                kb.id,
                kb.document_id,
                kb.course_id,
                kb.chunk_text,
                kb.chunk_index,
                kb.chunk_metadata,
                cd.file_name,
                cd.file_type
            FROM knowledge_base kb
            JOIN course_documents cd ON kb.document_id = cd.id
            WHERE cd.file_type = '.pptx'
            ORDER BY cd.created_at, kb.chunk_index;
        """)
        
        chunks = cursor.fetchall()
        print(f"   âœ… è¯»å–åˆ° {len(chunks)} ä¸ªæ–‡æœ¬å—")
        
        # 3. ç”Ÿæˆå‘é‡å¹¶ä¿å­˜åˆ°ChromaDB
        print("\n3ï¸âƒ£ ç”Ÿæˆå‘é‡å¹¶ä¿å­˜åˆ°ChromaDB...")
        
        success_count = 0
        fail_count = 0
        
        batch_ids = []
        batch_documents = []
        batch_embeddings = []
        batch_metadatas = []
        
        for i, chunk in enumerate(chunks, 1):
            kb_id, doc_id, course_id, chunk_text, chunk_index, metadata, file_name, file_type = chunk
            
            try:
                # ç”Ÿæˆå”¯ä¸€ID
                vector_id = f"{doc_id}_chunk_{chunk_index}"
                
                # ç”Ÿæˆå‘é‡
                embedding = vector_service.model.encode([chunk_text])[0]
                
                # å‡†å¤‡å…ƒæ•°æ®
                chunk_metadata = {
                    'document_id': str(doc_id),
                    'course_id': str(course_id),
                    'file_name': file_name,
                    'file_type': file_type,
                    'chunk_index': chunk_index
                }
                
                # æ·»åŠ åˆ°æ‰¹æ¬¡
                batch_ids.append(vector_id)
                batch_documents.append(chunk_text)
                batch_embeddings.append(embedding.tolist())
                batch_metadatas.append(chunk_metadata)
                
                # æ¯50ä¸ªæ‰¹é‡ä¿å­˜ä¸€æ¬¡
                if len(batch_ids) >= 50 or i == len(chunks):
                    collection.add(
                        ids=batch_ids,
                        documents=batch_documents,
                        embeddings=batch_embeddings,
                        metadatas=batch_metadatas
                    )
                    success_count += len(batch_ids)
                    print(f"   è¿›åº¦: {success_count}/{len(chunks)} ({success_count*100//len(chunks)}%)")
                    
                    # æ¸…ç©ºæ‰¹æ¬¡
                    batch_ids = []
                    batch_documents = []
                    batch_embeddings = []
                    batch_metadatas = []
                
            except Exception as e:
                fail_count += 1
                print(f"   âŒ å— {i} å¤±è´¥: {e}")
        
        cursor.close()
        conn.close()
        
        # 4. éªŒè¯ç»“æœ
        print("\n4ï¸âƒ£ éªŒè¯åŒæ­¥ç»“æœ...")
        new_count = collection.count()
        print(f"   âœ… ChromaDBç°æœ‰å‘é‡: {new_count} ä¸ª")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        if new_count > 0:
            results = collection.peek(limit=3)
            print(f"\n   ğŸ“„ ç¤ºä¾‹å‘é‡:")
            for i in range(min(3, len(results['ids']))):
                doc_id = results['ids'][i]
                metadata = results['metadatas'][i] if results['metadatas'] else {}
                doc_text = results['documents'][i][:100] if results['documents'] else ""
                
                print(f"\n   å‘é‡ {i+1}:")
                print(f"   æ–‡ä»¶: {metadata.get('file_name', 'unknown')}")
                print(f"   å—ç´¢å¼•: {metadata.get('chunk_index', 0)}")
                print(f"   å†…å®¹: {doc_text}...")
        
        print("\n" + "=" * 80)
        print(f"âœ… åŒæ­¥å®Œæˆ!")
        print(f"   æˆåŠŸ: {success_count} ä¸ª")
        print(f"   å¤±è´¥: {fail_count} ä¸ª")
        print("=" * 80)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åŒæ­¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("\nğŸš€ å¼€å§‹åŒæ­¥æ•°æ®åˆ°ChromaDB...\n")
    sync_to_chromadb()
    
    print("\n\nğŸ’¡ æç¤º:")
    print("   ç°åœ¨ä¸Šä¼ æ–°æ–‡ä»¶æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨:")
    print("   1. è§£ææ–‡ä»¶å†…å®¹ï¼ˆPPT/Word/PDFï¼‰")
    print("   2. ä¿å­˜åˆ°PostgreSQLæ•°æ®åº“")
    print("   3. ä¿å­˜åˆ°ChromaDBå‘é‡æ•°æ®åº“")
    print("   4. å¯ä»¥é€šè¿‡å‘é‡æ£€ç´¢æŸ¥è¯¢ç›¸å…³å†…å®¹")
